{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a1a016",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7f57c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in ./env/lib/python3.9/site-packages (0.1.20)\r\n",
      "Requirement already satisfied: tqdm in ./env/lib/python3.9/site-packages (from opendatasets) (4.42.1)\r\n",
      "Requirement already satisfied: click in ./env/lib/python3.9/site-packages (from opendatasets) (7.1.2)\r\n",
      "Requirement already satisfied: kaggle in ./env/lib/python3.9/site-packages (from opendatasets) (1.5.12)\r\n",
      "Requirement already satisfied: python-dateutil in ./env/lib/python3.9/site-packages (from kaggle->opendatasets) (2.8.0)\r\n",
      "Requirement already satisfied: certifi in ./env/lib/python3.9/site-packages (from kaggle->opendatasets) (2020.6.20)\r\n",
      "Requirement already satisfied: urllib3 in ./env/lib/python3.9/site-packages (from kaggle->opendatasets) (1.25.10)\r\n",
      "Requirement already satisfied: six>=1.10 in ./env/lib/python3.9/site-packages (from kaggle->opendatasets) (1.15.0)\r\n",
      "Requirement already satisfied: requests in ./env/lib/python3.9/site-packages (from kaggle->opendatasets) (2.24.0)\r\n",
      "Requirement already satisfied: python-slugify in ./env/lib/python3.9/site-packages (from kaggle->opendatasets) (5.0.2)\r\n",
      "Requirement already satisfied: text-unidecode>=1.3 in ./env/lib/python3.9/site-packages (from python-slugify->kaggle->opendatasets) (1.3)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./env/lib/python3.9/site-packages (from requests->kaggle->opendatasets) (2.10)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in ./env/lib/python3.9/site-packages (from requests->kaggle->opendatasets) (3.0.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36332c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "from distutils.dir_util import copy_tree\n",
    "import fnmatch \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "550bde79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " sunitaprakashkaggle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Kaggle Key: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7.00M/219M [00:00<00:03, 67.8MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading flower-classification.zip to ./flower-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219M/219M [00:02<00:00, 99.6MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/sauravagarwal/flower-classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a7636b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " sunitaprakashkaggle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Kaggle Key: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3.00M/363M [00:00<00:13, 27.9MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading flower-image-dataset.zip to ./flower-image-dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363M/363M [00:04<00:00, 78.3MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/aksha05/flower-image-dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36905ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "od.download(\"https://www.kaggle.com/alxmamaev/flowers-recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "574a3b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sunita/Desktop/sample_project\n",
      "/Users/sunita/Desktop/sample_project\n"
     ]
    }
   ],
   "source": [
    "#os.chdir\n",
    "main_dir = os.getcwd()\n",
    "print(main_dir)\n",
    "src_dir = os.getcwd()\n",
    "\n",
    "#dest_dir = os.mkdir('flower-dataset')\n",
    "print(src_dir)\n",
    "flower_classification_dir = src_dir+\"/flower-classification/flowers/flowers/flower_photos\"\n",
    "#print(flower_classification_dir)\n",
    "flower_image_dir = src_dir+\"/flower-image-dataset/flowers\"\n",
    "#print(flower_image_dir)\n",
    "#os.chdir(flower_image_dir)\n",
    "#print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dcc0997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bougainvillea\n",
      "/Users/sunita/Desktop/sample_project/flower-image-dataset/flowers\n",
      "dst2\n",
      "/Users/sunita/Desktop/sample_project/flower-dataset/bougainvillea/\n",
      "List of files containing \"file\" in them\n",
      "hibiscus\n",
      "/Users/sunita/Desktop/sample_project/flower-image-dataset/flowers\n",
      "dst3\n",
      "/Users/sunita/Desktop/sample_project/flower-dataset/hibiscus/\n",
      "List of files containing \"file\" in them\n"
     ]
    }
   ],
   "source": [
    "# create a dir where we want to copy dataset\n",
    "os.chdir(main_dir)\n",
    "if not os.path.exists('flower-dataset'):\n",
    "    dest_dir1 = os.mkdir('flower-dataset')\n",
    "final_dir = main_dir+\"/flower-dataset\" \n",
    "os.chdir(final_dir)\n",
    "myflower = ('roses', 'tulips', 'sunflowers')\n",
    "my_test_dir = ('test', 'train','validation')\n",
    "for x in myflower: \n",
    "  if not os.path.exists(x):\n",
    "    dest_dir = os.mkdir(x)\n",
    "    for y in my_test_dir:\n",
    "        src1 = flower_classification_dir+\"/\"+y+\"/\"+x\n",
    "        dst1 = final_dir+\"/\"+x\n",
    "        copy_tree(src1, dst1)  \n",
    "        \n",
    "\n",
    "flowernameb = \"bougainvillea\"\n",
    "if not os.path.exists(flowernameb):\n",
    "    print(flowernameb)\n",
    "    dest_dir2 = os.mkdir(flowernameb)\n",
    "    src2 = flower_image_dir\n",
    "    print(src2)\n",
    "    dst2 = final_dir+\"/\"+flowernameb+\"/\"\n",
    "    print(\"dst2\")\n",
    "    print(dst2)\n",
    "    print(\"List of files containing \\\"file\\\" in them\")\n",
    "   # os.chdir(srcdir)\n",
    "    os.chdir(src2)\n",
    "    files = fnmatch.filter(os.listdir('.'), \"b*\")\n",
    "    for file in files:\n",
    "        #print(file)\n",
    "        shutil.copy(file, dst2)\n",
    "        \n",
    "os.chdir(final_dir)        \n",
    "flowernameh = \"hibiscus\"\n",
    "if not os.path.exists(flowernameh):\n",
    "    print(flowernameh)\n",
    "    dest_dir3 = os.mkdir(flowernameh)\n",
    "    src3 = flower_image_dir\n",
    "    print(src3)\n",
    "    dst3 = final_dir+\"/\"+flowernameh+\"/\"\n",
    "    print(\"dst3\")\n",
    "    print(dst3)\n",
    "    print(\"List of files containing \\\"file\\\" in them\")\n",
    "    #os.chdir(srcdir)\n",
    "    os.chdir(src3)\n",
    "    files = fnmatch.filter(os.listdir('.'), \"hi*\")\n",
    "    for file in files:\n",
    "        #print(file)\n",
    "        shutil.copy(file, dst3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0ca97a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hibiscus\n"
     ]
    }
   ],
   "source": [
    "my_string = 'hibiscus_1.jpg'\n",
    "print(my_string.split('_')[0])\n",
    "!ls (h|b)*\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "404b8995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sunita/Desktop/sample_project/flower-dataset\n",
      "Total images:  74\n",
      "Training:  44\n",
      "Validation:  22\n",
      "Testing:  8\n",
      "Total images:  75\n",
      "Training:  45\n",
      "Validation:  22\n",
      "Testing:  8\n"
     ]
    }
   ],
   "source": [
    "#Path to the dataset folder\n",
    "rootdir= '/Users/sunita/Desktop/sample_project/flower-dataset' #path of the original folder\n",
    "print (rootdir)\n",
    "#classes = ['bougainvillea', 'hibiscus', 'roses','sunflowers', 'tulips']\n",
    "#classes = [ 'roses','sunflowers', 'tulips']\n",
    "classes = [ 'bougainvillea', 'hibiscus']\n",
    "\n",
    "for i in classes:\n",
    "    os.makedirs(rootdir +'/train/' + i)\n",
    "    os.makedirs(rootdir +'/test/' + i)\n",
    "    os.makedirs(rootdir +'/val/' + i)\n",
    "\n",
    "    source = rootdir + '/' + i\n",
    "\n",
    "    allFileNames = os.listdir(source)\n",
    "    np.random.shuffle(allFileNames)\n",
    "\n",
    "    train_ratio = 0.8\n",
    "    test_ratio = 0.1\n",
    "    val_ratio =  0.5\n",
    "\n",
    "                                                               \n",
    "    train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames),\n",
    "                                                              [int(len(allFileNames)* (1 - val_ratio + test_ratio)), \n",
    "                                                               int(len(allFileNames)* (1 - test_ratio))])\n",
    "                                                                                  \n",
    "    train_FileNames = [source+'/'+ name for name in train_FileNames.tolist()]\n",
    "    test_FileNames = [source+'/' + name for name in test_FileNames.tolist()]\n",
    "    val_FileNames = [source+'/' + name for name in val_FileNames.tolist()]\n",
    "        \n",
    "    \n",
    "    print('Total images: ', len(allFileNames))\n",
    "    print('Training: ', len(train_FileNames))\n",
    "    print('Validation: ', len(val_FileNames))\n",
    "    print('Testing: ', len(test_FileNames))\n",
    "    \n",
    "    for name in train_FileNames:\n",
    "      shutil.copy(name, rootdir +'/train/' + i)\n",
    "\n",
    "    for name in test_FileNames:\n",
    "      shutil.copy(name, rootdir +'/test/' + i)\n",
    "                                                                                  \n",
    "    for name in val_FileNames:\n",
    "        shutil.copy(name, rootdir +'/val/' + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip3 install lightning-grid --upgrade\n",
    "!grid datastore create --source ./flower-dataset --name datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e266788",
   "metadata": {},
   "outputs": [],
   "source": [
    "Finetuning\n",
    "First, finetune:\n",
    "\n",
    "import flash\n",
    "from flash.core.data.utils import download_data\n",
    "from flash.image import ImageClassificationData, ImageClassifier\n",
    "\n",
    "# 1. Download the data\n",
    "download_data(\"https://pl-flash-data.s3.amazonaws.com/hymenoptera_data.zip\", 'data/')\n",
    "\n",
    "# 2. Load the data\n",
    "datamodule = ImageClassificationData.from_folders(\n",
    "    train_folder=\"data/hymenoptera_data/train/\",\n",
    "    val_folder=\"data/hymenoptera_data/val/\",\n",
    "    test_folder=\"data/hymenoptera_data/test/\",\n",
    ")\n",
    "\n",
    "# 3. Build the model\n",
    "model = ImageClassifier(num_classes=datamodule.num_classes, backbone=\"resnet18\")\n",
    "\n",
    "# 4. Create the trainer. Run once on data\n",
    "trainer = flash.Trainer(max_epochs=1)\n",
    "\n",
    "# 5. Finetune the model\n",
    "trainer.finetune(model, datamodule=datamodule, strategy=\"freeze\")\n",
    "\n",
    "# 6. Save it!\n",
    "trainer.save_checkpoint(\"image_classification_model.pt\")\n",
    "Then use the finetuned model:\n",
    "\n",
    "from flash.image import ImageClassifier\n",
    "\n",
    "# load the finetuned model\n",
    "classifier = ImageClassifier.load_from_checkpoint('image_classification_model.pt')\n",
    "\n",
    "# predict!\n",
    "predictions = classifier.predict('data/hymenoptera_data/val/bees/65038344_52a45d090d.jpg')\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4defb23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install git+https://github.com/PyTorchLightning/lightning-flash.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c13e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flash\n",
    "from flash.core.data.utils import download_data\n",
    "from flash.image import ImageClassificationData, ImageClassifier\n",
    "download_data(\"https://pl-flash-data.s3.amazonaws.com/hymenoptera_data.zip\", '/Users/sunita/Desktop/sample_project/data/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64765e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
